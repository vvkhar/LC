{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from varclushi import VarClusHi\n",
    "from datetime import datetime\n",
    "from operator import attrgetter\n",
    "from scipy.stats.mstats import winsorize\n",
    "import statsmodels.api as sm\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import  GridSearchCV, cross_val_score, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "from category_encoders import WOEEncoder\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display settings \n",
    "display = pd.options.display\n",
    "display.max_columns = 1000\n",
    "display.max_rows = 1000\n",
    "display.max_colwidth = 199\n",
    "display.width = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file into a dataframe\n",
    "loanData = pd.read_csv('/Users/vibhor/Desktop/Models/LC/Loan_status_2007-2020Q3.gzip', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2925493, 141)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimensions of the dataframe\n",
    "loanData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2925493 entries, 0 to 105450\n",
      "Columns: 141 entries, id to debt_settlement_flag\n",
      "dtypes: float64(106), object(35)\n",
      "memory usage: 3.1+ GB\n"
     ]
    }
   ],
   "source": [
    "loanData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'url', 'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d', 'last_fico_range_high', 'last_fico_range_low', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'hardship_flag', 'hardship_type', 'hardship_reason', 'hardship_status', 'deferral_term', 'hardship_amount', 'hardship_start_date', 'hardship_end_date', 'payment_plan_start_date', 'hardship_length', 'hardship_dpd', 'hardship_loan_status', 'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', 'hardship_last_payment_amount', 'debt_settlement_flag']\n"
     ]
    }
   ],
   "source": [
    "#Retrieving the names of the columns in the datasets\n",
    "print(list(loanData.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loanData.duplicated().sum() # no duplicates (takes time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loanData.columns[loanData.isna().any()]) # Except the id column all others have N\n",
    "#to print them\n",
    "#loanData.columns[loanData.isna().any().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = loanData.isna().mean() #by variable this returns count(na)/total entries\n",
    "#missing_data.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Drop Features:  49\n",
      "['mths_since_last_delinq', 'mths_since_last_record', 'next_pymnt_d', 'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'open_acc_6m', 'open_act_il', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'mths_since_recent_bc_dlq', 'mths_since_recent_revol_delinq', 'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'hardship_type', 'hardship_reason', 'hardship_status', 'deferral_term', 'hardship_amount', 'hardship_start_date', 'hardship_end_date', 'payment_plan_start_date', 'hardship_length', 'hardship_dpd', 'hardship_loan_status', 'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', 'hardship_last_payment_amount']\n"
     ]
    }
   ],
   "source": [
    "drop_list = list(missing_data[missing_data > 0.2].index)\n",
    "print(\"\\n\\n Drop Features: \", len(drop_list))\n",
    "print(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_vars_remove = ['last_credit_pull_d','last_fico_range_high','last_fico_range_low','total_pymnt',\n",
    "                        'total_pymnt_inv','recoveries','collection_recovery_fee','out_prncp','out_prncp_inv',\n",
    "                        'total_rec_prncp','total_rec_int','last_pymnt_d','last_pymnt_amnt','next_pymnt_d',\n",
    "                        'total_rec_late_fee','hardship_flag','hardship_amount',\n",
    "                        'orig_projected_additional_accrued_interest','hardship_payoff_balance_amount',\n",
    "                        'hardship_last_payment_amount','debt_settlement_flag','hardship_type','hardship_reason',\n",
    "                        'hardship_status','deferral_term','hardship_start_date','hardship_end_date','payment_plan_start_date',\n",
    "                        'hardship_length','hardship_dpd','hardship_loan_status','installment','pymnt_plan',\n",
    "                        'acc_now_delinq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loanData.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_list + temporal_vars_remove, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied from Arun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleanup\n",
    "df['int_rate'] = df['int_rate'].str[:-1].astype(float) #Strip off the %sign\n",
    "df['revol_util'] = df['revol_util'].str[:-1].astype(float) #Strip off the %sign\n",
    "\n",
    "\n",
    "df['term'] = pd.to_numeric(df['term'].str.replace(' months', '')) #removing \"months\" and converting term to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning emp_length\n",
    "def clean_emp_length(data, emp_vari):\n",
    "    data['emp_length'].fillna(value = data[\"emp_length\"].mode()[0],inplace = True)\n",
    "    data['emp_length'].replace(to_replace = '< 1 year', value = '0', inplace = True)\n",
    "    data['emp_length'].replace(to_replace = '[^0-9]+', value = '', inplace = True, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cannot run the strptime function without replacing NaNs\n",
    "df['issue_d'].fillna(value = df[\"issue_d\"].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning up the date variables and also creating a loan vintage variable\n",
    "df['issue_date']  = df[\"issue_d\"].apply(lambda x: datetime.strptime(x, \"%b-%Y\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new vintage variable\n",
    "df['vintage'] = pd.to_datetime(df['issue_date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['earliest_cr_line'].fillna(value = df['earliest_cr_line'].mode()[0], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new variable for length of history at loan issue\n",
    "df['oldest_credit_date']  = df[\"earliest_cr_line\"].apply(lambda x: datetime.strptime(x, \"%b-%Y\"))\n",
    "\n",
    "\n",
    "df['credit_hist'] = (df.issue_date.dt.to_period('M') \\\n",
    "                                - df.oldest_credit_date.dt.to_period('M')).apply(attrgetter('n'))\n",
    "\n",
    "#If the attribute getter is not applied we get month ends instead of int like values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#winsorizing dti to upper and lower 0.1 percentile limits\n",
    "df['dti'] = winsorize(df['dti'], limits = (.001, 0.001)) \n",
    "\n",
    "#annual income has a 0 for some loans and that will create problems when creating pti and loan_to_inc variables \n",
    "#winsorizing annual income lower to 0.1 percentile limits\n",
    "\n",
    "df['annual_inc'] = winsorize(df['annual_inc'], limits = (.002, 0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['annual_inc'].describe(percentiles = [0.0001, 0.0005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funded Ratio - Hypothesis: If smaller fraction of loan gets funded that could point to a problem in obligor profile\n",
    "df['fund_ratio'] = df['funded_amnt'].div(df['loan_amnt'])\n",
    "\n",
    "#Loan to Income Ratio\n",
    "df['loan_to_inc'] = df['funded_amnt'].div(df['annual_inc'])\n",
    "\n",
    "#Monthly payment to income ratio\n",
    "df['pti'] = (12 * df['installment']).div(df['annual_inc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these variables in drop_list are important but they have just too many missing values to fill, thats why dropping them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,drop_list].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['initial_list_status'].value_counts() #does most of what fund ratio does, so dropping that below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### From Arun and judgment\n",
    "other_vars_remove  = ['url','oldest_credit_date','earliest_cr_line','policy_code','zip_code', 'sec_app_fico_range_low',\n",
    "                          'sec_app_fico_range_high','sec_app_earliest_cr_line','fico_range_low', 'fico_range_high',\n",
    "                     'annual_inc_joint','dti_joint','verification_status_joint', 'revol_bal_joint','sec_app_inq_last_6mths',\n",
    "                     'sec_app_mort_acc','sec_app_open_acc','sec_app_revol_util','sec_app_open_act_il', 'issue_d', 'issue_date'\n",
    "                      'sec_app_num_rev_accts','sec_app_chargeoff_within_12_mths','sec_app_collections_12_mths_ex_med',\n",
    "                       'addr_state','title','sub_grade', 'fund_ratio', 'emp_title', 'id']   \n",
    "                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "a_set = set(temporal_vars_remove1)\n",
    "b_set = set(temporal_vars_remove)\n",
    "if (a_set & b_set):\n",
    "    print(len(a_set & b_set))\n",
    "else:\n",
    "    print(\"No common elements\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Venn Diagram. Set function is not needed as there wont be any repeats in the lists, but used for completeness\n",
    "#In A but not in B or C + In B but not in C + C\n",
    "vars_dropped = list(set(drop_list) - set(other_vars_remove) - set(temporal_vars_remove)) + \\\n",
    "list(set(other_vars_remove) - set(temporal_vars_remove)) + temporal_vars_remove\n",
    "len(vars_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_variables = list(set(df.columns) - set(vars_dropped))\n",
    "len(retained_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retained_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.loc[:,retained_variables] #dataframe of retained variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable is loan_status. Understand what values it takes and its corresponding counts\n",
    "loanData['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new COflag\n",
    "keep_status = ['Charged Off', 'Fully Paid', 'Late (16-30 days)', 'Late (31-120 days)', 'Default', 'Current']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_small[df_small['loan_status'].isin(keep_status)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a chargeoff flag\n",
    "df_small['coFlag'] = 1\n",
    "df_small.loc[df_small['loan_status'].isin(['Fully Paid','Late (16-30 days)','Current']), 'coFlag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_means = (df_small._get_numeric_data().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.drop(['loan_status'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting number of object type (categorical) and numeric and getting a list of those\n",
    "#Counter(df_refined.dtypes)\n",
    "num_cols = df_small._get_numeric_data().columns\n",
    "cat_cols = list(set(df_small.columns) - set(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.loc[:, cat_cols].isna().any() #Cat cols dont have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_small.loc[:, num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small['emp_length'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in num_cols:\n",
    "    df_num[var].fillna(temp_means[var], inplace = True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df_small.loc[:, cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making Purpose into a 3 category variable. \n",
    "main_purpose = ['home_improvement', 'other', 'major_purchase' , 'small_business', 'car', 'medical', \\\n",
    "               'moving', 'vacation', 'house', 'wedding', 'renewable_energy', 'educational']\n",
    "\n",
    "df_cat['new_purpose'] = df_cat['purpose']\n",
    "\n",
    "\n",
    "df_cat.loc[df_cat['purpose'].isin(main_purpose), 'new_purpose'] = 'other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making home_ownership into a 3 category variable. \n",
    "main_purpose = ['ANY', 'NONE', 'OTHER' , 'OWN']\n",
    "\n",
    "df_cat['cat_home_ownership'] = df_cat['home_ownership']\n",
    "\n",
    "\n",
    "df_cat.loc[df_cat['home_ownership'].isin(main_purpose), 'cat_home_ownership'] = 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.drop(['home_ownership', 'purpose'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tempterm = df_num.pop('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_full = pd.concat([df_cat, df_tempterm], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_dummy = pd.get_dummies(df_cat_full, columns = ['application_type', 'verification_status', 'grade', \n",
    "                                                'initial_list_status', 'emp_length', 'new_purpose', \n",
    "                                                'cat_home_ownership', 'term'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y = df_num.pop('coFlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_num_std = sc.fit_transform(df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_std = pd.DataFrame(X_num_std, columns = df_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_std.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_dummy.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.concat([df_Y, df_cat_dummy,X_num_std], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_train = df_model[df_model.issue_date <= '2019-09-01']\n",
    "holdOut = df_model[df_model.issue_date > '2019-09-01'] #Out of time holdout\n",
    "trainSet, testSet = train_test_split(df_test_train, test_size = 0.3, random_state=693) #test and train splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet.drop(['issue_date'], axis = 1, inplace = True)\n",
    "testSet.drop(['issue_date'], axis = 1, inplace = True)\n",
    "holdOut.drop(['issue_date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ytrain = trainSet.pop('coFlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ytest = testSet.pop('coFlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_YHO = holdOut.pop('coFlag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ytrain = df_Ytrain.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ytrain['coFlag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "263761/(263761 + 1583739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [10, 1, .1, 0.01, .001]\n",
    "clf = LogisticRegression(penalty='l1',  C = c[4], class_weight = {0: .1427, 1: 0.8573}, solver='saga')\n",
    "clf.fit(trainSet, df_Ytrain)\n",
    "print('C:', c[4])\n",
    "print('Coefficient of each feature:', clf.coef_)\n",
    "print('Training accuracy:', clf.score(trainSet, df_Ytrain))\n",
    "print('Test accuracy:', clf.score(testSet, df_Ytest))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = np.abs(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = [importance > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "features = np.array(trainSet.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = ma.masked_array(features, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(testSet)\n",
    "cm = confusion_matrix(df_Ytest, predictions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = (cm.astype('float')/cm.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.xlabel('Actual label');\n",
    "plt.ylabel('Predicted label');\n",
    "all_sample_title = 'Confusion Matrix'\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_probs = [0 for _ in range(len(testSet))] # Naive predicted probabilities, all 0, which is the dominant class\n",
    "lr_probs = clf.predict_proba(testSet) #Logistic Regression predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.classes_\n",
    "lr_probs = lr_probs[:, 1]\n",
    "#Calculate and print auc score\n",
    "n_auc = roc_auc_score(df_Ytest, n_probs)\n",
    "lr_auc = roc_auc_score(df_Ytest, lr_probs)\n",
    "print('Naive: ROC AUC=', n_auc)\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fpr, n_tpr, _ = roc_curve(df_Ytest, n_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(df_Ytest, lr_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(n_fpr, n_tpr, linestyle='--', label='Naive')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(holdOut)\n",
    "cm = confusion_matrix(df_YHO, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Confusion Matrix'\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_probs = [0 for _ in range(len(holdOut))] # Naive predicted probabilities, all 0, which is the dominant class\n",
    "lr_probs = clf.predict_proba(holdOut) #Logistic Regression predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.classes_\n",
    "lr_probs = lr_probs[:, 1]\n",
    "#Calculate and print auc score\n",
    "n_auc = roc_auc_score(df_YHO, n_probs)\n",
    "lr_auc = roc_auc_score(df_YHO, lr_probs)\n",
    "print('Naive: ROC AUC=%.3f' % (n_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.transpose().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = importance.reshape((81,))\n",
    "c = coefficient.reshape((81,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.DataFrame({'features':features, 'importance':t, 'coefficient' : c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp.sort_values(by = ['importance'], ascending = False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
